{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPCfvKURPF9sNelOHxjTz/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TarteTatin1212/face_recognition_script2/blob/main/face_recognition_script2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "71WgvWJNTUi_",
        "outputId": "b2a4522f-773d-4c2b-91f4-a69bef4bfec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Horita_Semi/Senior_Project')\n"
      ],
      "metadata": {
        "id": "Y1Ttp1-rclEL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd  # 現在のカレントディレクトリを表示\n",
        "!ls   # カレントディレクトリのファイルリストを表示\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YpKZGAKcf8a",
        "outputId": "9b9937b7-4242-4f89-e3a6-fc5e1013c583"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Horita_Semi/Senior_Project\n",
            "api_key.txt\t\t\tmerged_data.csv\t\t       Untitled0.ipynb\n",
            "contents_search.ipynb\t\tmerge_face_and_metadata.ipynb  youtube_thumbnail_downloader.ipynb\n",
            "data_analytics.ipynb\t\tmodels\t\t\t       youtube_utils.ipynb\n",
            "datasets\t\t\t__pycache__\t\t       YuNetFaceDetectionResults\n",
            "FaceRecognitionResults\t\tsaved_data\t\t       yunet.ipynb\n",
            "face_recognition_script2.ipynb\tsenior_project_main.ipynb      yunet.py\n",
            "face_recognition_script.ipynb\tthumbnails\t\t       課題点.gdoc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nbimporter\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from yunet import YuNet  # yunet.pyからYuNetクラスをインポート"
      ],
      "metadata": {
        "id": "ydqeeypbuuRi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# バウンディングボックスと信頼度スコアを描画する関数\n",
        "def visualize(image, results, box_color=(255, 0, 0), text_color=(255, 0, 0)):\n",
        "    # 引数で渡された画像のコピーを作成\n",
        "    output = image.copy()\n",
        "\n",
        "    # 検出結果(results)の各要素に対してループ処理\n",
        "    for det in results:\n",
        "        # detからバウンディングボックスの座標を抽出し、整数型にキャスト\n",
        "        bbox = det[0:4].astype(np.int32)\n",
        "\n",
        "        # 抽出したバウンディングボックスの座標を使用して、画像に矩形を描画\n",
        "        cv.rectangle(output,\n",
        "                     (bbox[0], bbox[1]),  # 矩形の左上の座標\n",
        "                     (bbox[0] + bbox[2], bbox[1] + bbox[3]),  # 矩形の右下の座標\n",
        "                     box_color,  # 矩形の色\n",
        "                     2)  # 矩形の線の太さ\n",
        "\n",
        "        # detの最後の要素から信頼度スコアを抽出\n",
        "        conf = det[-1]\n",
        "\n",
        "        # 抽出した信頼度スコアを画像にテキストとして描画\n",
        "        cv.putText(output,\n",
        "                   '{:.4f}'.format(conf),  # テキストとして描画する信頼度スコア\n",
        "                   (bbox[0], bbox[1] + 12),  # テキストの位置（バウンディングボックスの左上から少し下）\n",
        "                   cv.FONT_HERSHEY_DUPLEX,  # フォントスタイル\n",
        "                   0.5,  # フォントサイズ\n",
        "                   text_color)  # テキストの色\n",
        "\n",
        "    # 処理が完了した画像を返す\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "OzScsqP7uY61"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YuNetモデルのファイルパスを指定\n",
        "# このパスはGoogle Drive内の特定のディレクトリにあるYuNetモデルへのパス\n",
        "model_path = '/content/drive/MyDrive/Horita_Semi/Senior_Project/models/face_detection_yunet_2023mar.onnx'\n",
        "\n",
        "# YuNetモデルのインスタンスを作成\n",
        "model = YuNet(\n",
        "    modelPath=model_path,  # モデルファイルへのパス\n",
        "    inputSize=[320, 320],  # モデルの入力サイズ。ここでは320x320ピクセル\n",
        "    confThreshold=0.9,     # 検出信頼度の閾値。0.9は高い信頼度を意味する\n",
        "    nmsThreshold=0.3,      # 非最大抑制（Non-Maximum Suppression）の閾値。0.3は標準的な値\n",
        "    topK=5000              # 検出された顔の最大数。ここでは5000個まで検出可能\n",
        ")\n"
      ],
      "metadata": {
        "id": "3jS3jzAnvT6m"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "y1irvvOvpUb1"
      },
      "outputs": [],
      "source": [
        "# 画像が保存されているディレクトリのパスを指定\n",
        "directory_path = '/content/drive/MyDrive/Horita_Semi/Senior_Project/FaceRecognitionResults/UnrecognizedFaces'\n",
        "\n",
        "# 指定されたディレクトリ内のすべてのJPEG画像ファイルのリストを取得\n",
        "image_files = glob.glob(\n",
        "    os.path.join(directory_path, '*.jpg')\n",
        ")\n",
        "\n",
        "# 取得した画像ファイルのリストに対してループ処理\n",
        "for file in image_files:\n",
        "    # 画像ファイルを読み込み\n",
        "    image = cv.imread(file)\n",
        "\n",
        "    # 画像が正しく読み込まれなかった場合の処理\n",
        "    if image is None:\n",
        "        print(f\"Failed to load image {file}\")\n",
        "        continue\n",
        "\n",
        "    # 画像処理を試みる\n",
        "    try:\n",
        "        # 画像の高さと幅を取得\n",
        "        h, w, _ = image.shape\n",
        "\n",
        "        # YuNetモデルに画像サイズを設定\n",
        "        model.setInputSize([w, h])\n",
        "\n",
        "        # モデルを使って画像内の顔を検出\n",
        "        results = model.infer(image)\n",
        "\n",
        "        # 検出された顔の数を出力\n",
        "        # print('{} faces detected in {}.'.format(len(results), file))\n",
        "\n",
        "        # 検出された顔がある場合の処理\n",
        "        if len(results) > 0:\n",
        "            # 検出された顔にバウンディングボックスを描画\n",
        "            image_with_boxes = visualize(image, results)\n",
        "\n",
        "            # 加工された画像を保存するパスを設定\n",
        "            save_path = os.path.join(\n",
        "                '/content/drive/MyDrive/Horita_Semi/Senior_Project/FaceRecognitionResults/RecognizedFace',\n",
        "                os.path.basename(file)\n",
        "            )\n",
        "\n",
        "            # 加工された画像を指定されたパスに保存\n",
        "            cv.imwrite(save_path, image_with_boxes)\n",
        "\n",
        "    # 画像処理中にエラーが発生した場合の処理\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {file}: {e}\")\n"
      ]
    }
  ]
}