{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMs4g/wTXn9SwziXFyEYVyp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TarteTatin1212/face_recognition_script2/blob/main/face_recognition_script2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"/content/drive/MyDrive/Horita_Semi/Senior_Project/models/\"\n"
      ],
      "metadata": {
        "id": "ydqeeypbuuRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# YuNet モデルのURL\n",
        "yunet_model_url = 'https://raw.githubusercontent.com/ShiqiYu/libfacedetection.train/master/onnx/yunet_s_640_640.onnx'\n",
        "\n",
        "# モデルをダウンロードして保存するファイルパス\n",
        "model_save_path = '/content/drive/MyDrive//Horita_Semi/Senior_Project/models/yunet.onnx'\n",
        "\n",
        "# モデルのダウンロード\n",
        "response = requests.get(yunet_model_url)\n",
        "if response.status_code == 200:\n",
        "    with open(model_save_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(\"YuNet モデルがダウンロードされました。\")\n",
        "else:\n",
        "    print(\"YuNet モデルのダウンロードに失敗しました。ステータスコード:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzScsqP7uY61",
        "outputId": "99582c5e-30d5-4eb2-c3f4-245e88b597cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YuNet モデルがダウンロードされました。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def load_yunet_model(model_path):\n",
        "    try:\n",
        "        model = cv2.dnn.readNetFromONNX(model_path)\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"モデルのロード中にエラーが発生しました: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_model_layer_names(model):\n",
        "    try:\n",
        "        layer_names = model.getLayerNames()\n",
        "        return layer_names\n",
        "    except Exception as e:\n",
        "        print(f\"レイヤー名の取得中にエラーが発生しました: {e}\")\n",
        "        return []\n",
        "\n",
        "# YuNet モデルのパスを指定\n",
        "model_path = '/content/drive/MyDrive//Horita_Semi/Senior_Project/models/yunet.onnx'\n",
        "\n",
        "# YuNet モデルをロード\n",
        "model = load_yunet_model(model_path)\n",
        "if model is not None:\n",
        "    # モデルのレイヤー名を表示\n",
        "    layer_names = get_model_layer_names(model)\n",
        "    if layer_names:\n",
        "        for i, layer_name in enumerate(layer_names):\n",
        "            print(i, layer_name)\n",
        "    else:\n",
        "        print(\"レイヤー名は取得できませんでした。\")\n",
        "else:\n",
        "    print(\"モデルはロードできませんでした。\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jS3jzAnvT6m",
        "outputId": "414425a4-86bd-4b8a-c784-90ae64b1306d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 onnx_node!Conv_0\n",
            "1 onnx_node!Relu_1\n",
            "2 onnx_node!Conv_2\n",
            "3 onnx_node!Conv_3\n",
            "4 onnx_node!Relu_4\n",
            "5 onnx_node!MaxPool_5\n",
            "6 onnx_node!Conv_6\n",
            "7 onnx_node!Conv_7\n",
            "8 onnx_node!Relu_8\n",
            "9 onnx_node!Conv_9\n",
            "10 onnx_node!Conv_10\n",
            "11 onnx_node!Relu_11\n",
            "12 onnx_node!Conv_12\n",
            "13 onnx_node!Conv_13\n",
            "14 onnx_node!Relu_14\n",
            "15 onnx_node!Conv_15\n",
            "16 onnx_node!Conv_16\n",
            "17 onnx_node!Relu_17\n",
            "18 onnx_node!MaxPool_18\n",
            "19 onnx_node!Conv_19\n",
            "20 onnx_node!Conv_20\n",
            "21 onnx_node!Relu_21\n",
            "22 onnx_node!Conv_22\n",
            "23 onnx_node!Conv_23\n",
            "24 onnx_node!Relu_24\n",
            "25 onnx_node!MaxPool_25\n",
            "26 onnx_node!Conv_26\n",
            "27 onnx_node!Conv_27\n",
            "28 onnx_node!Relu_28\n",
            "29 onnx_node!Conv_29\n",
            "30 onnx_node!Conv_30\n",
            "31 onnx_node!Relu_31\n",
            "32 onnx_node!MaxPool_32\n",
            "33 onnx_node!Conv_33\n",
            "34 onnx_node!Conv_34\n",
            "35 onnx_node!Relu_35\n",
            "36 onnx_node!Conv_36\n",
            "37 onnx_node!Conv_37\n",
            "38 onnx_node!Relu_38\n",
            "39 onnx_node!Conv_39\n",
            "40 onnx_node!Conv_40\n",
            "41 onnx_node!Relu_41\n",
            "42 onnx_node!Resize_43\n",
            "43 onnx_node!Add_44\n",
            "44 onnx_node!Conv_45\n",
            "45 onnx_node!Conv_46\n",
            "46 onnx_node!Relu_47\n",
            "47 onnx_node!Resize_49\n",
            "48 onnx_node!Add_50\n",
            "49 onnx_node!Conv_51\n",
            "50 onnx_node!Conv_52\n",
            "51 onnx_node!Relu_53\n",
            "52 onnx_node!Conv_54\n",
            "53 onnx_node!Conv_55\n",
            "54 onnx_node!Conv_56\n",
            "55 onnx_node!Conv_57\n",
            "56 onnx_node!Conv_58\n",
            "57 onnx_node!Conv_59\n",
            "58 onnx_node!Conv_60\n",
            "59 onnx_node!Conv_61\n",
            "60 onnx_node!Conv_62\n",
            "61 onnx_node!Conv_63\n",
            "62 onnx_node!Conv_64\n",
            "63 onnx_node!Conv_65\n",
            "64 onnx_node!Conv_66\n",
            "65 onnx_node!Conv_67\n",
            "66 onnx_node!Conv_68\n",
            "67 onnx_node!Conv_69\n",
            "68 onnx_node!Conv_70\n",
            "69 onnx_node!Conv_71\n",
            "70 onnx_node!Conv_72\n",
            "71 onnx_node!Conv_73\n",
            "72 onnx_node!Conv_74\n",
            "73 onnx_node!Conv_75\n",
            "74 onnx_node!Conv_76\n",
            "75 onnx_node!Conv_77\n",
            "76 onnx_node!Transpose_78\n",
            "77 onnx_node!Reshape_84\n",
            "78 onnx_node!Sigmoid_85\n",
            "79 onnx_node!Transpose_86\n",
            "80 onnx_node!Reshape_92\n",
            "81 onnx_node!Sigmoid_93\n",
            "82 onnx_node!Transpose_94\n",
            "83 onnx_node!Reshape_100\n",
            "84 onnx_node!Sigmoid_101\n",
            "85 onnx_node!Transpose_102\n",
            "86 onnx_node!Reshape_108\n",
            "87 onnx_node!Sigmoid_109\n",
            "88 onnx_node!Transpose_110\n",
            "89 onnx_node!Reshape_116\n",
            "90 onnx_node!Sigmoid_117\n",
            "91 onnx_node!Transpose_118\n",
            "92 onnx_node!Reshape_124\n",
            "93 onnx_node!Sigmoid_125\n",
            "94 onnx_node!Transpose_126\n",
            "95 onnx_node!Reshape_132\n",
            "96 onnx_node!Transpose_133\n",
            "97 onnx_node!Reshape_139\n",
            "98 onnx_node!Transpose_140\n",
            "99 onnx_node!Reshape_146\n",
            "100 onnx_node!Transpose_147\n",
            "101 onnx_node!Reshape_153\n",
            "102 onnx_node!Transpose_154\n",
            "103 onnx_node!Reshape_160\n",
            "104 onnx_node!Transpose_161\n",
            "105 onnx_node!Reshape_167\n",
            "106 cls_8\n",
            "107 cls_16\n",
            "108 cls_32\n",
            "109 obj_8\n",
            "110 obj_16\n",
            "111 obj_32\n",
            "112 bbox_8\n",
            "113 bbox_16\n",
            "114 bbox_32\n",
            "115 kps_8\n",
            "116 kps_16\n",
            "117 kps_32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1irvvOvpUb1",
        "outputId": "b8bee6ea-1b0d-4e61-daed-c190c73496f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.8.1.78)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xusGhSV6qFLb",
        "outputId": "5720aa5d-35b3-4a16-cf85-c6d4490f5b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_face_detection_yunet(images_dir, base_dir):\n",
        "    # YuNetモデルの初期化\n",
        "    try:\n",
        "        model = cv2.dnn.readNetFromONNX('/content/drive/MyDrive/Horita_Semi/Senior_Project/models/yunet.onnx')\n",
        "    except Exception as e:\n",
        "        print(f\"モデルの読み込み中にエラーが発生しました: {e}\")\n",
        "        return\n",
        "\n",
        "    # ディレクトリを作成\n",
        "    new_folder = os.path.join(base_dir, 'YuNetFaceDetectionResults')\n",
        "    detected_faces_dir = os.path.join(new_folder, 'DetectedFaces')\n",
        "    undetected_faces_dir = os.path.join(new_folder, 'UndetectedFaces')\n",
        "    os.makedirs(detected_faces_dir, exist_ok=True)\n",
        "    os.makedirs(undetected_faces_dir, exist_ok=True)\n",
        "\n",
        "    # images_dirにある各ファイルに対して処理を行う\n",
        "    for filename in os.listdir(images_dir):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            filepath = os.path.join(images_dir, filename)\n",
        "\n",
        "            image = cv2.imread(filepath)\n",
        "            if image is None:\n",
        "                print(f\"画像が読み込めません: {filepath}\")\n",
        "                continue\n",
        "\n",
        "            h, w = image.shape[:2]\n",
        "\n",
        "            # 画像の前処理\n",
        "            blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(320, 320), mean=(104.0, 177.0, 123.0))\n",
        "            model.setInput(blob)\n",
        "\n",
        "            # 顔検出の実行\n",
        "            confidences, boxes = model.forward([\"conf\", \"loc\"])\n",
        "\n",
        "            if len(boxes) > 0:\n",
        "                for i in range(boxes.shape[0]):\n",
        "                    box = boxes[i, :]\n",
        "                    x1, y1, x2, y2 = box[0] * w, box[1] * h, box[2] * w, box[3] * h\n",
        "                    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "                save_path = os.path.join(detected_faces_dir, filename)\n",
        "                cv2.imwrite(save_path, image)\n",
        "            else:\n",
        "                shutil.copy(filepath, os.path.join(undetected_faces_dir, filename))\n"
      ],
      "metadata": {
        "id": "EEsdE-tjqGtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # ディレクトリを変更\n",
        "    images_directory = '/content/drive/MyDrive/Horita_Semi/Senior_Project/thumbnails'\n",
        "    base_directory = '/content/drive/MyDrive/Horita_Semi/Senior_Project'\n",
        "\n",
        "    # perform_face_detection_yunet関数を呼び出す\n",
        "    perform_face_detection_yunet(images_directory, base_directory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "_ShkULKdqIMk",
        "outputId": "f0aa8a07-d0f1-4ed0-f1d8-412be97b37a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-83e29aaf4eeb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# perform_face_detection_yunet関数を呼び出す\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mperform_face_detection_yunet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-bfae1e5af97d>\u001b[0m in \u001b[0;36mperform_face_detection_yunet\u001b[0;34m(images_dir, base_dir)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# 顔検出の実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mconfidences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"conf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/dnn/src/net_impl.cpp:279: error: (-204:Requested object was not found) Layer with requested id=-1 not found in function 'getLayerData'\n"
          ]
        }
      ]
    }
  ]
}